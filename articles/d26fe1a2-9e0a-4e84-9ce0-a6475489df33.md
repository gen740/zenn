---
title: "GP についての覚書き"
emoji: "📏"
type: "tech"
topics: ["math"]
published: false
---

----------

## 線形回帰

### モデル

$$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \cdots + \beta_p X_p + \varepsilon \\
\left( Y = X\beta + \varepsilon \right)$$

### パラメータ推定量

$$\hat{\beta} = (X^TX)^{-1}X^Ty$$

### 導出

$$E = (y - X\beta)^2 \\
\frac{\partial E}{\partial \beta} = - \left( X^T(y - X\beta) + (y^T-X^T\beta^T)X \right)$$

----------

## ロジスティック回帰

### モデル

$$\log\left(\frac{p}{1-p}\right) = X\beta \\
p = \frac{\exp\left(X\beta\right)}{1 + \exp\left(X\beta\right)}$$

### 尤度

$$\prod^n_{i=1}p_i^{Y_i}(1-p_i)^{1-Y_i}$$

----------

## カーネル回帰

### モデル

$$\hat{y} = (k(x^{(0)},x), k(x^{(1)},x), k(x^{(2)}, x), \cdots) \begin{pmatrix}
\alpha_0 \\
\alpha_1 \\
\alpha_2 \\
\vdots
\end{pmatrix} \\
K = \begin{pmatrix}
  k(x^{(0)},x^{(0)}) & k(x^{(0)}, x^{(1)}) & \cdots \\
k(x^{(1)}, x^{(0)}) & k(x^{(1)}, x^{(1)}) & \\
\vdots & & \ddots
\end{pmatrix}\\

\vec{y} = K\vec{\alpha}$$

### バラメーター推定量

* 二乗誤差

$$\begin{align*}
R(\alpha) &= (\vec{y} - K\vec{\alpha})^T(\vec{y} - K\vec{\alpha}) \\
\alpha &= (K^TK)^{-1}K^T\vec{y} = K^{-1}\vec{y}
\end{align*}$$

* 正則化

$$\begin{align*}
R(\alpha_n) &= (\vec{y_n} - K_{n,n}\vec{\alpha_n})^T(\vec{y_n} - K_{n,n}\vec{\alpha_n}) + \lambda\vec{\alpha_n}^TK_{n,n}\vec{\alpha_n} \\
\vec{\alpha}_n &= (K_{n,n}+\lambda I)^{-1}\vec{y_n} \\
\vec{m_m} &= K^T_{n,m}(K_{n,n} + \sigma^2I_n)^{-1}\vec{y}_n \\
\vec{v} &= K_{m,m} - K^T_{n,m}(K_{n,n} + \sigma^2I_n)^{-1}K_{n,m}
\end{align*}$$

### Kernel

* Mater52Kernel

$$\begin{align*}
k(r) &= \left( 1 + \sqrt{5}r + \frac{5}{3}r^2 \right) \exp(-\sqrt{5}r)\\
\frac{dk}{dr} &= - \frac{5}{3} \left( \sqrt{5}r + 1 \right) \exp(-\sqrt{5}r)
\end{align*}$$

$$K(r, r^*) = \begin{pmatrix}
k((r_1- r^*_1)^2) & k((r_1, r^*_2)^2) & \cdots \\
k((r_2-r^*_1)^2) & k((r_2-r^*_2)^2) & \cdots \\
\vdots & \vdots & \ddots
\end{pmatrix}$$

* posterior

$$A_{mean} = K$$

## 補足

### 疑似逆行列